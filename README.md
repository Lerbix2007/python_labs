# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã

## –õ–∞–±–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1

```python
def min_max(nums):
    if not nums:
        raise ValueError("–°–ø–∏—Å–æ–∫ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    return (min(nums), max(nums))


def unique_sorting(nums):
    unique_nums = set(nums)      
    sorted_nums = sorted(unique_nums)  
    return sorted_nums


def flatten(mat):
    result = []
    for row in mat:
        if not isinstance(row, (list, tuple)):
            raise TypeError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂, –ø–æ–ª—É—á–µ–Ω {type(row).__name__}")
        result.extend(row)
    return result


def main():    
    
    # –¢–µ—Å—Ç min_max
    print("\n1. –§—É–Ω–∫—Ü–∏—è min_max(nums)")
    test_cases_minmax = [
        [3, -1, 5, 5, 0],
        [42],
        [-5, -2, -9],
        [1.5, 2, 2.0, -3.1]
    ]
    
    for nums in test_cases_minmax:
        result = min_max(nums)
        print(f"  {nums} ‚Üí {result}")
    
    # –¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º
    try:
        min_max([])
    except ValueError as e:
        print(f"  [] ‚Üí ValueError: {e}")
    
    # –¢–µ—Å—Ç unique_sorting
    print("\n2. –§—É–Ω–∫—Ü–∏—è unique_sorting(nums)")
    test_cases_unique = [
        [3, 1, 2, 1, 3],
        [],
        [-1, -1, 0, 2, 2],
        [1.0, 1, 2.5, 2.5, 0]
    ]
    
    for nums in test_cases_unique:
        result = unique_sorting(nums)
        print(f"  {nums} ‚Üí {result}")
    
    # –¢–µ—Å—Ç flatten
    print("\n3. –§—É–Ω–∫—Ü–∏—è flatten(mat)")
    test_cases_flatten = [
        [[1, 2], [3, 4]],
        [[1, 2], (3, 4, 5)],
        [[1], [], [2, 3]]
    ]
    
    for mat in test_cases_flatten:
        result = flatten(mat)
        print(f"  {mat} ‚Üí {result}")
    
    # –¢–µ—Å—Ç —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ç–∏–ø–æ–º
    try:
        flatten([[1, 2], "ab"])
    except TypeError as e:
        print(f"  [[1, 2], \"ab\"] ‚Üí TypeError: {e}")
    
    
if __name__ == "__main__":
    main()
```
![alt text](images/lab02/ex01.png)

### –ó–∞–¥–∞–Ω–∏–µ 2

```python
def is_rectangular(mat):
    if not mat:
        return True
    
    first_len = len(mat[0])
    for row in mat:
        if len(row) != first_len:
            return False
    return True


def transpose(mat):
    if not is_rectangular(mat):
        raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–π")
    
    result = []
    for i in range(len(mat[0])):
        new_row = []
        for j in range(len(mat)):
            new_row.append(mat[j][i])
        result.append(new_row)
    return result


def row_sums(mat):
    if not is_rectangular(mat):
        raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–π")
    
    sums = []
    for row in mat:
        sums.append(sum(row))
    return sums


def print_matrix(mat, title=""):
    if title:
        print(title)
    for row in mat:
        print(row)


def main():
    print("–û–ü–ï–†–ê–¶–ò–ò –° –ú–ê–¢–†–ò–¶–ê–ú–ò")
    
    # –¢–µ—Å—Ç–æ–≤–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    
    print("\n–ò—Å—Ö–æ–¥–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞:")
    print_matrix(matrix)
    
    print("\n–¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞:")
    print_matrix(transpose(matrix))
    
    print("\n–°—É–º–º—ã —Å—Ç—Ä–æ–∫:")
    print(row_sums(matrix))
    
    # –¢–µ—Å—Ç —Å –æ—à–∏–±–∫–æ–π
    print("\n–¢–µ—Å—Ç —Å —Ä–≤–∞–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ–π:")
    try:
        wrong_matrix = [[1, 2], [3]]
        transpose(wrong_matrix)
    except ValueError as e:
        print(f"–û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
```
![alt text](images/lab02/ex02.png)

### –ó–∞–¥–∞–Ω–∏–µ 3

```python
def format_record(rec):
    fio, group, gpa = rec
    
    # –û—á–∏—Å—Ç–∫–∞ –§–ò–û
    fio_parts = fio.strip().split()
    fio_parts = [part.capitalize() for part in fio_parts]
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ñ–∞–º–∏–ª–∏—é –∏ –∏–Ω–∏—Ü–∏–∞–ª—ã
    surname = fio_parts[0]
    initials = []
    for i in range(1, len(fio_parts)):
        if fio_parts[i]:
            initials.append(fio_parts[i][0].upper() + ".")
    
    if initials:
        formatted_fio = f"{surname} {''.join(initials)}"
    else:
        formatted_fio = surname
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É
    formatted_str = f"{formatted_fio}, –≥—Ä. {group}, GPA {gpa:.2f}"
    
    return formatted_str


def main():
    print("–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–ü–ò–°–ï–ô –°–¢–£–î–ï–ù–¢–û–í")
    
    test_cases = [
        ("–†–æ—Å–∏–Ω—Å–∫–∏–π –õ–µ–æ–Ω–∏–¥ –ê–Ω–¥—Ä–µ–µ–≤–∏—á", "BIVT-25", 4.6),
        ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0),
        ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999),
        ("–°–º–∏—Ä–Ω–æ–≤ –ê–ª–µ–∫—Å–µ–π", "–ë–ò–í–¢-22", 4.5),
    ]
    
    for rec in test_cases:
        result = format_record(rec)
        print(f"–í—Ö–æ–¥: {rec}")
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}\n")


if __name__ == "__main__":
    main()
```


![alt text](images/lab02/ex03.png)

## –õ–∞–±–∞ 3
### –ó–∞–¥–∞–Ω–∏–µ 1
```python
import re

def normalize(text, casefold=True, yo2e=True):
    if not text:
        return ""
    
    result = text
    
    if yo2e:
        result = result.replace('—ë', '–µ').replace('–Å', '–ï')
    
    if casefold:
        result = result.casefold()
    
    result = result.strip()
    result = re.sub(r'\s+', ' ', result)
    
    return result

def tokenize(text):
    if not text:
        return []
    
    return re.findall(r'[\w\-]+', text)

def count_freq(tokens):
    freq = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1
    return freq

def top_n(freq, n=5):
    if not freq:
        return []
    
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]

def test_functions():
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–£–ù–ö–¶–ò–ô")
    print("=" * 50)
    
    # –¢–µ—Å—Ç—ã –¥–ª—è normalize
    print("\n1. normalize():")
    test_cases = [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ]
    
    for input_text, expected in test_cases:
        result = normalize(input_text)
        print(f"  '{input_text}' ‚Üí '{result}'")
    
    # –¢–µ—Å—Ç—ã –¥–ª—è tokenize
    print("\n2. tokenize():")
    test_cases = [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ]
    
    for input_text, expected in test_cases:
        result = tokenize(input_text)
        print(f"  '{input_text}' ‚Üí {result}")
    
    # –¢–µ—Å—Ç—ã –¥–ª—è count_freq + top_n
    print("\n3. count_freq() + top_n():")
    
    tokens1 = ["a", "b", "a", "c", "b", "a"]
    freq1 = count_freq(tokens1)
    top1 = top_n(freq1, 2)
    print(f"  {tokens1} ‚Üí {top1}")
    
    tokens2 = ["bb", "aa", "bb", "aa", "cc"]
    freq2 = count_freq(tokens2)
    top2 = top_n(freq2, 2)
    print(f"  {tokens2} ‚Üí {top2}")
def demo_text_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ 2 –∑–∞–¥–∞–Ω–∏–∏"""
    demo_text = "–ü—Ä–∏–≤–µ—Ç –ú–∏—Ä!!! –ü—Ä–∏–≤–µ—Ç!.."

if __name__ == "__main__":
    test_functions()
```
![alt text](images/lab03/ex01.png)
### –ó–∞–¥–∞–Ω–∏–µ 2
```python
import sys
from scr.lib.text import normalize, tokenize, count_freq, top_n 

def main():
    demo_text = "–ü—Ä–∏–≤–µ—Ç –ú–∏—Ä!!! –ü—Ä–∏–≤–µ—Ç!.."
    print("-" * 30)
    print("\n–ü—Ä–∏–º–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
    print("-" * 30)
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏–∏ 
    normalized_text = normalize(demo_text)
    tokens = tokenize(normalized_text)
    frequencies = count_freq(tokens)
    top_words = top_n(frequencies, 5)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(frequencies)}")
    print("–¢–æ–ø-5:")
    
    for word, count in top_words:
        print(f"{word}:{count}")

if __name__ == "__main__":
    main()
```
![alt text](images/lab03/ex02.png)

## –õ–∞–±–∞ 4
### –ó–∞–¥–∞–Ω–∏–µ 1

```python
import csv
from pathlib import Path
def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    with open(path, 'r', encoding=encoding) as f:
        return f.read()

def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    if rows and len(set(len(row) for row in rows)) != 1:
        raise ValueError("–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É")
    
    with open(path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        if header:
            writer.writerow(header)
        writer.writerows(rows)

if __name__ == "__main__":
    try:
        txt = read_text('src/lab04/Text.test')
        print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ: {txt}")
    except FileNotFoundError:
        print("–§–∞–π–ª text.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    write_csv([("word", "count"), ("test", 3)], "table.csv")  
    print("—Ñ–∞–π–ª csv —Å–æ–∑–¥–∞–Ω!")
```
![alt text](images/lab04/ex01.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
import sys, os, csv
from collections import Counter

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from scr.lab03.ex01 import normalize, tokenize
except ImportError as e:
    sys.exit(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")

def main():
    input_file = 'src/lab04/Text.test'
    output_file = 'src/lab04/Table.csv'

    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
        if not text.strip():
            sys.exit("–§–∞–π–ª –ø—É—Å—Ç–æ–π")
    except Exception as e:
        sys.exit(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {input_file}: {e}")
    
    try:
        normalized = normalize(text)
        words = tokenize(normalized)
        if not words:
            sys.exit("–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        word_freq = Counter(words)
    except Exception as e:
        sys.exit(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")


    try:
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['word', 'count'])
            for word, count in sorted(word_freq.items(), key=lambda x: (-x[1], x[0])):
                writer.writerow([word, count])
    except Exception as e:
        sys.exit(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {output_file}: {e}")
    
    top5 = sorted(word_freq.items(), key=lambda x: (-x[1], x[0]))[:5]
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(words)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(word_freq)}")
    print('–¢–æ–ø 5:')
    k = 0
    print(f'{"—Å–ª–æ–≤–æ:":^15} |{"—á–∞—Å—Ç–æ—Ç–∞":^15}')
    print(f"{'----------'*3:^30}")
    for word, counts in top5:
        if k == 5:
            break
        k += 1
        print(f'{word:^15} |{counts:^15}')

if __name__ == "__main__":
    main()
```
![alt text](images/lab04/ex02.png)
## –õ–∞–±–∞ 5
### –ó–∞–¥–∞–Ω–∏–µ 1
```python
import csv, json
from pathlib import Path


def json_to_csv(json_path: str, csv_path: str) -> None:

    json_file = Path(json_path)
    csv_file = Path(csv_path)
    print(f" –ò—â–µ–º —Ñ–∞–π–ª: {json_path}")
    if not json_file.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {json_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if json_file.suffix.lower() != ".json":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è .json")
    
    try:
        with json_file.open('r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")
    
    if not data:
        raise ValueError("–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
    
    if not isinstance(data, list):
        raise ValueError("JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤")
    
    if not all(isinstance(item, dict) for item in data):
        raise ValueError("–í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")
    
    all_keys = set()
    for item in data:
        all_keys.update(item.keys())

    if data:
        first_item_keys = list(data[0].keys())
        remaining_keys = sorted(all_keys - set(first_item_keys))
        fieldnames = first_item_keys + remaining_keys
    else:
        fieldnames = sorted(all_keys)
    # –ó–∞–ø–∏—Å—å –≤ CSV
    try:
        with csv_file.open('w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for row in data:
                complete_row = {key: row.get(key, '') for key in fieldnames}
                writer.writerow(complete_row)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ CSV: {e}")

def csv_to_json(csv_path: str, json_path: str) -> None:
  
    csv_file = Path(csv_path)
    json_file = Path(json_path)
    
    if not csv_file.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {csv_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if csv_file.suffix.lower() != '.csv':
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è .csv")
    
    try:
        with csv_file.open('r', encoding='utf-8') as f:
            reader = csv.DictReader(f, delimiter='\t')
            if reader.fieldnames is None:
                raise ValueError("CSV —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞")
            
            data = list(reader)
            
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")

    if not data:
        raise ValueError("–ü—É—Å—Ç–æ–π CSV —Ñ–∞–π–ª")

    try:
        with json_file.open('w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ JSON: {e}")

json_to_csv(r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\people.json", r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\out\people_from_json.csv")
csv_to_json(r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\people.csv", r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\out\people_from_csv.json")
```
![alt text](images/lab05/Ex01_1.png)
![alt text](images/lab05/Ex01_2.png)
### –ó–∞–¥–∞–Ω–∏–µ 2
```python
import csv, json
from pathlib import Path
from openpyxl import Workbook


def json_to_csv(json_path: str, csv_path: str) -> None:
    json_file = Path(json_path)
    csv_file = Path(csv_path)
    print(f" –ò—â–µ–º —Ñ–∞–π–ª: {json_path}")
    if not json_file.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {json_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if json_file.suffix.lower() != ".json":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è .json")

    try:
        with json_file.open('r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")

    if not data:
        raise ValueError("–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")

    if not isinstance(data, list):
        raise ValueError("JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤")

    if not all(isinstance(item, dict) for item in data):
        raise ValueError("–í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")

    all_keys = set()
    for item in data:
        all_keys.update(item.keys())

    if data:
        first_item_keys = list(data[0].keys())
        remaining_keys = sorted(all_keys - set(first_item_keys))
        fieldnames = first_item_keys + remaining_keys
    else:
        fieldnames = sorted(all_keys)

    try:
        with csv_file.open('w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for row in data:
                complete_row = {key: row.get(key, '') for key in fieldnames}
                writer.writerow(complete_row)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ CSV: {e}")


def csv_to_json(csv_path: str, json_path: str) -> None:
    csv_file = Path(csv_path)
    json_file = Path(json_path)

    if not csv_file.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {csv_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if csv_file.suffix.lower() != '.csv':
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è .csv")

    try:
        with csv_file.open('r', encoding='utf-8') as f:
            reader = csv.DictReader(f, delimiter='\t')
            if reader.fieldnames is None:
                raise ValueError("CSV —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞")

            data = list(reader)

    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")

    if not data:
        raise ValueError("–ü—É—Å—Ç–æ–π CSV —Ñ–∞–π–ª")

    try:
        with json_file.open('w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ JSON: {e}")


def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CSV –≤ XLSX.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç openpyxl. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫.
    """
    csv_file = Path(csv_path)
    xlsx_file = Path(xlsx_path)
    if csv_file.suffix.lower() != ".csv":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .csv")
    if xlsx_file.suffix.lower() != ".xlsx":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .xlsx")
    if not csv_file.exists():
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    with csv_file.open(encoding="utf-8") as f:
        reader = list(csv.reader(f, delimiter='\t'))
        if not reader:
            raise ValueError("–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª")

    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"

    for row in reader:
        ws.append(row)

    for col in ws.columns:
        max_length = 0
        column = col[0].column_letter
        for cell in col:
            value = str(cell.value) if cell.value is not None else ""
            if len(value) > max_length:
                max_length = len(value)
        adjusted_width = max(max_length + 2, 8)
        ws.column_dimensions[column].width = adjusted_width

    wb.save(xlsx_file)


json_to_csv(r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\people.json",
            r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\out\people_from_json.csv")
csv_to_json(r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\people.csv",
            r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\out\people_from_csv.json")
csv_to_xlsx(r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\people.csv",
            r"C:\Users\Librix\Desktop\labs\python_labs\data\samples\out\people_from_csv.xlsx")
```
![alt text](images/lab05/Ex02.png)

## –õ–∞–±–∞ 6
### –ó–∞–¥–∞–Ω–∏–µ 1

```python
import sys, os
import argparse
from pathlib import Path
from lib.text_stats import stats_text

from lib.text_lib import normalize, tokenize, count_freq, top_n
from lib.io_txt_csv import read_text


def check_file(file_path: str) -> bool:
    if not os.path.exists(file_path):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª '{file_path}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç", file=sys.stderr)
        return False
    if not os.path.isfile(file_path):
        print(f"–û—à–∏–±–∫–∞: '{file_path}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–∞–π–ª–æ–º", file=sys.stderr)
        return False

    return True


def cat_command(input_file: str, number_lines: bool = False):
    if not check_file(input_file):
        sys.exit(1)

    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_number, line in enumerate(f, start=1):
                if number_lines:
                    print(f"{line_number:6d}  {line}", end='')
                else:
                    print(line, end='')
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}", file=sys.stderr)
        sys.exit(1)


def stats_command(input_file: str, top_n: int = 5):
    if not check_file(input_file):
        sys.exit(1)

    if top_n <= 0:
        print("–û—à–∏–±–∫–∞: –∑–Ω–∞—á–µ–Ω–∏–µ --top –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º", file=sys.stderr)
        sys.exit(1)

    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
            stats_text(text, top_n)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {e}", file=sys.stderr)
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    subparsers = parser.add_subparsers(dest="command")

    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True)
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")
    stats_parser.add_argument("--input", required=True)
    stats_parser.add_argument("--top", type=int, default=5)

    args = parser.parse_args()

    if args.command == "cat":
        if not check_file(args.input):
            sys.exit(1)

        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                if args.n:
                    for line_number, line in enumerate(f, start=1):
                        print(f"{line_number:6d}  {line}", end='')
                else:
                    for line in f:
                        print(line, end='')
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}", file=sys.stderr)
            sys.exit(1)

    elif args.command == "stats":
        if not check_file(args.input):
            sys.exit(1)

        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                text = f.read()
                for e in top_n(count_freq(tokenize(normalize(text))), args.top):
                    print(e[0], e[1])
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {e}", file=sys.stderr)
            sys.exit(1)


if __name__ == "__main__":
    main()
```
#### —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–≤–æ–¥ 1-–≥–æ –∑–∞–¥–∞–Ω–∏—è
![alt text](images/lab06/ex01.png)
#### –≤—ã–≤–æ–¥ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã help
![alt text](images/lab06/ex01help.png)
### –ó–∞–¥–∞–Ω–∏–µ 2
```python
import sys, argparse
from pathlib import Path
import os
import contextlib
import io

from src.lab05.ex01 import json_to_csv, csv_to_json
from src.lab05.ex02 import csv_to_xlsx
from src.lab06.ex01 import check_file

def silent_check_file(file_path: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –±–µ–∑ –≤—ã–≤–æ–¥–∞ –Ω–∞ —ç–∫—Ä–∞–Ω"""
    return os.path.exists(file_path) and os.path.isfile(file_path)

def run_silently(func, *args, **kwargs):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –±–µ–∑ –≤—ã–≤–æ–¥–∞ –Ω–∞ —ç–∫—Ä–∞–Ω"""
    with contextlib.redirect_stdout(io.StringIO()):
        with contextlib.redirect_stderr(io.StringIO()):
            return func(*args, **kwargs)

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    sub = parser.add_subparsers(dest="cmd")

    p1 = sub.add_parser("json2csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ç–æ—Ä –∏–∑ JSON –≤ CSV")
    p1.add_argument("--in", dest="input", required=True)
    p1.add_argument("--out", dest="output", required=True)

    p2 = sub.add_parser("csv2json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ç–æ—Ä –∏–∑ CSV –≤ JSON")
    p2.add_argument("--in", dest="input", required=True)
    p2.add_argument("--out", dest="output", required=True)

    p3 = sub.add_parser("csv2xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ç–æ—Ä –∏–∑ CSV –≤ Excel")
    p3.add_argument("--in", dest="input", required=True)
    p3.add_argument("--out", dest="output", required=True)

    args = parser.parse_args()

    try:
        if args.cmd == "json2csv":
            if not silent_check_file(args.input):
                print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {args.input} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                sys.exit(1)

            run_silently(json_to_csv, args.input, args.output)
            print(f"–£—Å–ø–µ—à–Ω–æ: JSON -> CSV")

        elif args.cmd == "csv2json":
            if not silent_check_file(args.input):
                print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {args.input} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                sys.exit(1)

            run_silently(csv_to_json, args.input, args.output)
            print(f"–£—Å–ø–µ—à–Ω–æ: CSV -> JSON")

        elif args.cmd == "csv2xlsx":
            if not silent_check_file(args.input):
                print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {args.input} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                sys.exit(1)

            run_silently(csv_to_xlsx, args.input, args.output)
            print(f"–£—Å–ø–µ—à–Ω–æ: CSV -> XLSX")

        else:
            print("–û—à–∏–±–∫–∞: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞")
            sys.exit(1)

        return 0

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
#### —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–≤–æ–¥ 2-–≥–æ –∑–∞–¥–∞–Ω–∏—è
![alt text](images/lab06/ex02.png)
#### –≤—ã–≤–æ–¥ help 2-–≥–æ –∑–∞–¥–∞–Ω–∏—è
![alt text](images/lab06/ex02help.png)
## –õ–∞–±–∞ 7
### –ó–∞–¥–∞–Ω–∏–µ 1
```python
import pytest
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from lib.text_lib import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),  # –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç + —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),  # –±—É–∫–≤—ã —Å —Ä–∞–∑–Ω—ã–º —Ä–µ–≥–∏—Å—Ç—Ä–æ–º
        ("Hello\r\nWorld", "hello world"),  # –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),  # –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        ("", ""),  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        ("\t\n   ", ""),  # —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    ],
)
def test_normalize(source, expected):
    assert normalize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),  # –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
        ("–æ–¥–∏–Ω, –¥–≤–∞, —Ç—Ä–∏!", ["–æ–¥–∏–Ω", "–¥–≤–∞", "—Ç—Ä–∏"]),  # —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        ("", []),  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        ("   –º–Ω–æ–≥–æ   –ø—Ä–æ–±–µ–ª–æ–≤   ", ["–º–Ω–æ–≥–æ", "–ø—Ä–æ–±–µ–ª–æ–≤"]),  # –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã
        ("—Å–ª–æ–≤–æ —Å–ª–æ–≤–æ —Å–ª–æ–≤–æ", ["—Å–ª–æ–≤–æ", "—Å–ª–æ–≤–æ", "—Å–ª–æ–≤–æ"]),  # –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞
    ],
)
def test_tokenize(source, expected):
    assert tokenize(source) == expected


@pytest.mark.parametrize(
    "tokens, expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        ([], {}),
    ],
)
def test_count_freq(tokens, expected):
    assert count_freq(tokens) == expected


@pytest.mark.parametrize(
    "freq_dict, expected",
    [
        ({"a": 3, "b": 2, "c": 1}, [("a", 3), ("b", 2), ("c", 1)]),  # –æ–±—ã—á–Ω—ã–π —Å–ª—É—á–∞–π
        (
            {
                "—è–±–ª–æ–∫–æ": 2,
                "–∞–ø–µ–ª—å—Å–∏–Ω": 2,
                "–±–∞–Ω–∞–Ω": 2,
            },  # –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —á–∞—Å—Ç–æ—Ç—ã ‚Üí —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
            [("–∞–ø–µ–ª—å—Å–∏–Ω", 2), ("–±–∞–Ω–∞–Ω", 2), ("—è–±–ª–æ–∫–æ", 2)],
        ),
        ({}, []),  # –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        (
            {
                "a": 5,
                "b": 4,
                "c": 3,
                "d": 2,
                "e": 1,
                "f": 1,
            },  # –±–æ–ª—å—à–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏ n=5
            [("a", 5), ("b", 4), ("c", 3), ("d", 2), ("e", 1)],
        ),
    ],
)
def test_top_n(freq_dict, expected):
    assert top_n(freq_dict) == expected

```
![alt text](images/lab07/ex01.png)
### –ó–∞–¥–∞–Ω–∏–µ 2
```python
import json
import csv
import pytest
from pathlib import Path
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from lib.json_csv import json_to_csv, csv_to_json


def test_json_to_csv_roundtrip(tmp_path: Path):  # –£—Å–ø–µ—à–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è JSON to CSV
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"

    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]

    src.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")

    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert rows[0]["name"] == "Alice"
    assert rows[1]["age"] == "25"


def test_csv_to_json_roundtrip(tmp_path: Path):  # –£—Å–ø–µ—à–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV to JSON
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()
        writer.writerow({"name": "Alice", "age": "22"})
        writer.writerow({"name": "Bob", "age": "25"})

    csv_to_json(str(src), str(dst))

    data = json.loads(dst.read_text(encoding="utf-8"))

    assert isinstance(data, list)
    assert len(data) == 2
    assert data[0]["name"] == "Alice"
    assert data[1]["age"] == "25"


def test_json_to_csv_invalid_json(
    tmp_path: Path,
):  # –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª "—Å–ª–æ–º–∞–Ω"/–Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–∞–π–ª–æ–º JSON
    src = tmp_path / "broken.json"
    dst = tmp_path / "output.csv"
    src.write_text("not a json", encoding="utf-8")

    with pytest.raises(ValueError):
        json_to_csv(str(src), str(dst))


def test_csv_to_json_invalid_csv(
    tmp_path: Path,
):  # –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª "—Å–ª–æ–º–∞–Ω"/–Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–∞–π–ª–æ–º CSV
    src = tmp_path / "broken.csv"
    dst = tmp_path / "output.json"
    src.write_text(",,,\n,,", encoding="utf-8")

    with pytest.raises(ValueError):
        csv_to_json(str(src), str(dst))


def test_missing_file():  # –í—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    with pytest.raises(FileNotFoundError):
        json_to_csv("no_such_file.json", "output.csv")


def test_invalid_suffix_to_json(tmp_path: Path):  # –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ CSV
    src = tmp_path / "input.txt"
    dst = tmp_path / "output.json"
    src.write_text("This is 100% json, trust me", encoding="utf-8")
    with pytest.raises(ValueError):
        csv_to_json(str(src), str(dst))
```
![alt text](images/lab07/ex02.png)
#### –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ black .
![alt text](<images/lab07/black --check ..png>)
![alt text](images/lab07/black.png)